{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300G\t/mnt/data/projects/precovery/precovery_data\n",
      "888M\t/mnt/data/projects/precovery/precovery_data/index.db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "\n",
    "MPC_DATA_DIR = \"mpc_data\"\n",
    "UOD = \"/mnt/data/projects/precovery/precovery_data\"\n",
    "FRAME_DB = os.path.join(UOD, \"index.db\")\n",
    "! du -sh {UOD}\n",
    "! du -sh {FRAME_DB}\n",
    "\n",
    "os.environ[\"OORB_DATA\"] = \"/home/moeyensj/software/oorb/share/oorb/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPCORB_FILE = os.path.join(MPC_DATA_DIR, \"mpcorb_extended.json\")\n",
    "if not os.path.exists(MPCORB_FILE):\n",
    "    ! wget https://minorplanetcenter.net/Extended_Files/mpcorb_extended.json.gz\n",
    "    ! gunzip mpcorb_extended.json.gz\n",
    "    ! cp mpcorb_extended.json {MPC_DATA_DIR}/mpcorb_extended.json\n",
    "    ! rm mpcorb_extended.json.gz\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MPC orbits: 1298457\n",
      "MPC orbits observed since 2010: 1291106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.50315269e+00,  2.64980455e-01,  4.69470013e-01,\n",
       "        -1.47228816e-03, -1.10463649e-02, -7.80683705e-05],\n",
       "       [-1.11238330e+00,  1.53946174e+00, -9.71053802e-01,\n",
       "        -1.10274737e-02, -5.27296083e-03,  4.60346390e-03],\n",
       "       [ 1.44565128e+00,  1.33085314e+00, -3.61024533e-01,\n",
       "        -9.86783949e-03,  9.22837891e-03, -1.69414305e-03],\n",
       "       ...,\n",
       "       [-1.92119886e+00,  5.04558475e-01,  2.25208855e-02,\n",
       "        -2.54295007e-03, -1.02969229e-02,  4.71847442e-03],\n",
       "       [-1.31287291e+00,  5.90954243e-01, -4.22139862e-01,\n",
       "        -6.90281154e-03, -8.07382729e-03,  1.20935143e-02],\n",
       "       [-1.46891458e+00, -6.52424566e-02,  6.66683163e-01,\n",
       "         3.72923655e-03, -1.45222657e-02,  2.21371533e-03]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thor.orbits import Orbits\n",
    "from thor.utils.mpc import readMPCOrbitCatalog\n",
    "\n",
    "mpc_orbits_df = readMPCOrbitCatalog(MPCORB_FILE)\n",
    "print(f\"Total MPC orbits: {len(mpc_orbits_df)}\")\n",
    "\n",
    "# Filter the MPC orbits to only contain those observed since 2010\n",
    "year_last_observed = mpc_orbits_df[\"last_obs\"].str[:4].astype(int)\n",
    "mpc_orbits_df = mpc_orbits_df[year_last_observed >= 2010]\n",
    "print(f\"MPC orbits observed since 2010: {len(mpc_orbits_df)}\")\n",
    "\n",
    "mpc_orbits = Orbits.fromMPCOrbitCatalog(mpc_orbits_df)\n",
    "mpc_orbits.keplerian\n",
    "mpc_orbits.cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sql.connect(FRAME_DB)\n",
    "frames = pd.read_sql(\"\"\"SELECT * FROM frames WHERE dataset_id = 'nsc'\"\"\", con)\n",
    "frames.insert(2, \"month\", frames[\"data_uri\"].str.split(\"/\").str[1])\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = frames[\"month\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from precovery.precovery_db import PrecoveryDatabase\n",
    "import dataclasses\n",
    "\n",
    "def get_observations_for_month(month):\n",
    "\n",
    "    db = PrecoveryDatabase.from_dir(UOD, create=False, mode=\"r\", allow_version_mismatch=True)\n",
    "    con = sql.connect(FRAME_DB)\n",
    "    frames_window = frames[frames[\"month\"] == month]\n",
    "    ids = frames_window[\"id\"].values.tolist()\n",
    "    frames_window = list(db.frames.idx.get_frames_by_id(ids))\n",
    "\n",
    "    observation_dfs = []\n",
    "\n",
    "    for f in frames_window:\n",
    "        mjds = []\n",
    "        ras = []\n",
    "        decs = []\n",
    "        ra_sigmas = []\n",
    "        dec_sigmas = []\n",
    "        mags = []\n",
    "        mag_sigmas = []\n",
    "        ids = []\n",
    "        for o in db.frames.iterate_observations(f):\n",
    "            mjds.append(o.mjd)\n",
    "            ras.append(o.ra)\n",
    "            decs.append(o.dec)\n",
    "            ra_sigmas.append(o.ra_sigma)\n",
    "            dec_sigmas.append(o.dec_sigma)\n",
    "            mags.append(o.mag)\n",
    "            mag_sigmas.append(o.mag_sigma)\n",
    "            ids.append(o.id.decode())\n",
    "\n",
    "        observations_df = pd.DataFrame({\n",
    "            \"obs_id\" : ids,\n",
    "            \"mjd_utc\": mjds,\n",
    "            \"ra\": ras,\n",
    "            \"dec\": decs,\n",
    "            \"ra_sigma\": ra_sigmas,\n",
    "            \"dec_sigma\": dec_sigmas,\n",
    "            \"mag\": mags,\n",
    "            \"mag_sigma\": mag_sigmas\n",
    "        })\n",
    "        for i, (key, value) in enumerate(dataclasses.asdict(f).items()):\n",
    "            if type(value) == b'':\n",
    "                value = value.decode()\n",
    "            observations_df.insert(i, key, value)\n",
    "        observation_dfs.append(observations_df)\n",
    "\n",
    "    observations = pd.concat(observation_dfs, ignore_index=True)\n",
    "    observations.rename(columns={\"id\": \"frame_id\"}, inplace=True)\n",
    "    observations.drop(columns=[\"dataset_id\", \"data_uri\", \"data_offset\", \"data_length\"], inplace=True)\n",
    "    observations.sort_values(by=[\"mjd_utc\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    con.close()\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:precovery:Version mismatch: \n",
      "Running version: 0.2.dev160+g9988cf8\n",
      "Database version: 0.2.dev159+gc091c7b\n",
      "allow_version_mismatch=True, so continuing.\n"
     ]
    }
   ],
   "source": [
    "from astropy.time import Time\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import warnings\n",
    "import logging\n",
    "from thor import selectTestOrbits\n",
    "from thor import preprocessObservations\n",
    "from thor import rangeAndShift\n",
    "from thor.orbits import propagateOrbits\n",
    "from thor.orbits import generateEphemeris\n",
    "\n",
    "orbits = []\n",
    "\n",
    "logger = logging.getLogger(\"thor\")\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i, month in enumerate(months):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        if not os.path.exists(f\"test_orbits_{month}.parquet\"):\n",
    "            # Read the observations for the month\n",
    "            observations = get_observations_for_month(month)\n",
    "\n",
    "            # Calculate the middle point of the month\n",
    "            mjd_middle_point = (observations[\"mjd_utc\"].max() - observations[\"mjd_utc\"].min()) / 2 + observations[\"mjd_utc\"].min()\n",
    "            delta_middle_point = np.abs(observations[\"mjd_utc\"].values - mjd_middle_point)\n",
    "            closest_to_middle_idx = np.argsort(delta_middle_point)[0]\n",
    "            middle_point = Time(\n",
    "                observations[\"mjd_utc\"].values[closest_to_middle_idx:closest_to_middle_idx+1],\n",
    "                scale=\"utc\", \n",
    "                format=\"mjd\"\n",
    "            )\n",
    "\n",
    "            if i > 0:\n",
    "                # Load propagated orbits from the previous month to reduce propagation time\n",
    "                file_name = os.path.join(MPC_DATA_DIR, f\"mpcorb_propagated_{months[i-1]}.parquet\")\n",
    "                mpcorb_propagated = pd.read_parquet(file_name)\n",
    "                mpc_orbits = Orbits.from_df(mpcorb_propagated)\n",
    "\n",
    "            # Propagate the MPC orbit catalog to the middle point of the month\n",
    "            file_name = os.path.join(MPC_DATA_DIR, f\"mpcorb_propagated_{month}.parquet\")\n",
    "            if not os.path.exists(file_name):\n",
    "                mpcorb_propagated = propagateOrbits(\n",
    "                    mpc_orbits,\n",
    "                    middle_point,\n",
    "                    num_jobs=60,\n",
    "                    parallel_backend=\"mp\",\n",
    "                    chunk_size=100,\n",
    "                    backend=\"PYOORB\",\n",
    "                    backend_kwargs={\"dynamical_model\" : \"N\"}\n",
    "                )\n",
    "                mpcorb_propagated.to_parquet(file_name)\n",
    "                \n",
    "            else:\n",
    "                mpcorb_propagated = pd.read_parquet(file_name)\n",
    "            print(\"Orbits propagated: \", len(mpcorb_propagated))\n",
    "\n",
    "            # Generate the ephemeris for the middle point of the month for the MPC orbit catalog\n",
    "            observers = {\n",
    "                \"W84\" : middle_point\n",
    "            }\n",
    "            file_name = os.path.join(MPC_DATA_DIR, f\"mpcorb_ephemeris_{month}.parquet\")\n",
    "            if not os.path.exists(file_name):\n",
    "                mpcorb_eph = generateEphemeris(\n",
    "                    Orbits.from_df(mpcorb_propagated),\n",
    "                    observers,\n",
    "                    num_jobs=60,\n",
    "                    parallel_backend=\"mp\",\n",
    "                    chunk_size=100,\n",
    "                    backend=\"PYOORB\",\n",
    "                    backend_kwargs={\"dynamical_model\" : \"N\"}\n",
    "                )\n",
    "                mpcorb_eph.to_parquet(file_name)\n",
    "                \n",
    "            else:\n",
    "                mpcorb_eph = pd.read_parquet(file_name)\n",
    "            print(\"Ephemerides generated: \", len(mpcorb_eph))\n",
    "\n",
    "            # Preprocess the observations into the format required by THOR\n",
    "            column_mapping = {\n",
    "                \"obs_id\" : \"obs_id\",\n",
    "                \"mjd\" : \"mjd_utc\",\n",
    "                \"RA_deg\" : \"ra\",\n",
    "                \"Dec_deg\" : \"dec\",\n",
    "                \"RA_sigma_deg\" : \"ra_sigma\",\n",
    "                \"Dec_sigma_deg\" : \"dec_sigma\",\n",
    "                \"observatory_code\" : \"obscode\",\n",
    "                \"obj_id\" : None,\n",
    "                \"mag\" : \"mag\",\n",
    "                \"mag_sigma\" : \"mag_sigma\",\n",
    "                \"filter\" : \"filter\",\n",
    "            }   \n",
    "            astrometric_errors = None\n",
    "            mjd_scale = \"utc\"\n",
    "\n",
    "            preprocessed_observations, preprocessed_associations = preprocessObservations(\n",
    "                observations,\n",
    "                column_mapping,\n",
    "                mjd_scale=mjd_scale,\n",
    "                astrometric_errors=astrometric_errors\n",
    "            )\n",
    "\n",
    "            NSIDE = 32\n",
    "            test_orbits_df = selectTestOrbits(\n",
    "                preprocessed_observations, \n",
    "                mpcorb_eph, \n",
    "                patch_algorithm=\"healpix\", \n",
    "                patch_algorithm_kwargs={\n",
    "                    \"nside\" : NSIDE, \n",
    "                    \"nest\" : True\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Select two patches at random\n",
    "            patches = test_orbits_df[\"patch_id\"].unique()\n",
    "            patch_ids = np.random.choice(patches, 1)\n",
    "            patches_selected = test_orbits_df[test_orbits_df[\"patch_id\"].isin(patch_ids)].reset_index(drop=True)\n",
    "\n",
    "            # For each orbit in the select patches, project the observations\n",
    "            # and calculate the number of exposures and observations\n",
    "            orbits_month = []\n",
    "            for orbit in patches_selected[\"orbit_id\"].unique():\n",
    "\n",
    "                orbit_df = patches_selected[patches_selected[\"orbit_id\"] == orbit]\n",
    "                projected_observations = rangeAndShift(\n",
    "                    preprocessed_observations,\n",
    "                    Orbits.from_df(orbit_df),\n",
    "                    num_jobs=20,\n",
    "                    parallel_backend=\"mp\",\n",
    "                    cell_area=10,\n",
    "                )\n",
    "\n",
    "                num_exposures = projected_observations[\"mjd_utc\"].nunique()\n",
    "                num_obs = len(projected_observations)\n",
    "\n",
    "                orbit_df.insert(0, \"month\", month)\n",
    "                orbit_df.insert(3, \"num_exposures\", num_exposures)\n",
    "                orbit_df.insert(4, \"num_obs\", num_obs)\n",
    "\n",
    "                orbits.append(orbit_df)\n",
    "                orbits_month.append(orbit_df)\n",
    "\n",
    "            orbits_month = pd.concat(orbits_month, ignore_index=True)\n",
    "            orbits_month.to_parquet(f\"test_orbits_{month}.parquet\")\n",
    "\n",
    "    \n",
    "\n",
    "orbits = pd.concat(orbits, ignore_index=True)\n",
    "orbits.to_parquet(\"test_orbits.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thor_main_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
